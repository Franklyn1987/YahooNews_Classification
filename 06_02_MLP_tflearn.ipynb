{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- encoding: utf-8 -*-\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tflearn\n",
    "from sklearn import metrics\n",
    "from tensorflow.contrib import learn\n",
    "import pandas as pd\n",
    "# import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "# 获取数据\n",
    "\n",
    "# mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# log_dir = 'log_dir/'\n",
    "# max_steps = 1000\n",
    "# learning_rate = 0.001\n",
    "# dropout = 0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 划分数据集\n",
    "def splitData(label,text):\n",
    "\n",
    "    line_count = len(label)\n",
    "    rarray=np.random.random(size=line_count)\n",
    "    train_set = []\n",
    "    train_tag = []\n",
    "    test_set = []\n",
    "    test_tag = []\n",
    "    for i in range(line_count):\n",
    "        if rarray[i]<0.8:\n",
    "            train_set.append(text[i,:])\n",
    "            train_tag.append(label[i])\n",
    "        else:\n",
    "            test_set.append(text[i,:])\n",
    "            test_tag.append(label[i])\n",
    "    return (train_set,train_tag,test_set,test_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainModel_dense(train_set,train_label,test_set,test_label):\n",
    "    # 定义深度神经网络\n",
    "    input_layer = tflearn.input_data(shape=[None, 400])\n",
    "    \n",
    "    dense1 = tflearn.fully_connected(input_layer, 400, activation='tanh',regularizer='L2', weight_decay=0.001)\n",
    "    dropout1 = tflearn.dropout(dense1, 0.8)\n",
    "    \n",
    "    dense2 = tflearn.fully_connected(dropout1, 400, activation='tanh',regularizer='L2', weight_decay=0.001)\n",
    "    dropout2 = tflearn.dropout(dense2, 0.8)\n",
    "    \n",
    "    softmax = tflearn.fully_connected(dropout2, 10, activation='softmax')\n",
    "\n",
    "    # Regression using SGD with learning rate decay and Top-3 accuracy\n",
    "    sgd = tflearn.SGD(learning_rate=0.1, lr_decay=0.96, decay_step=3000)\n",
    "    top_k = tflearn.metrics.Top_k(3)\n",
    "    net = tflearn.regression(softmax, optimizer=sgd, metric=top_k,loss='categorical_crossentropy')\n",
    "\n",
    "    # Training\n",
    "    # tensorboard_verbose=3 可视化\n",
    "    model = tflearn.DNN(net, tensorboard_verbose=3)\n",
    "    model.fit(train_set, train_label, n_epoch=30, validation_set=(test_set, test_label),show_metric=True, run_id=\"dense_model\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainModel_simple(train_set,train_label,test_set,test_label):\n",
    "    # 定义深度神经网络\n",
    "    input_layer = tflearn.input_data(shape=[None, 400])\n",
    "    \n",
    "    dense1 = tflearn.fully_connected(input_layer, 64)\n",
    "    dropout1 = tflearn.dropout(dense1, 0.8)\n",
    "    \n",
    "    dense2 = tflearn.fully_connected(dropout1, 64)\n",
    "    dropout2 = tflearn.dropout(dense2, 0.8)\n",
    "    \n",
    "    softmax = tflearn.fully_connected(dropout2, 10, activation='softmax')\n",
    "\n",
    "    # Regression using SGD with learning rate decay and Top-3 accuracy\n",
    "    net = tflearn.regression(softmax, optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "    # Training\n",
    "    model = tflearn.DNN(net)\n",
    "    model.fit(train_set, train_label, n_epoch=20, validation_set=(test_set, test_label),show_metric=True, run_id=\"dense_model\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    \n",
    "    lsiData = \"./data/textData_LSI.npy\"\n",
    "    ldaData = \"./data/textData_LDA.npy\"\n",
    "    targetData = \"./data/target.npy\"\n",
    "    \n",
    "    # 读入数据 原数据矩阵需要做转置\n",
    " \n",
    "    lsiDataSet = np.load(lsiData).T\n",
    "    \n",
    "    ldaDataSet = np.load(ldaData).T\n",
    "    \n",
    "    # 读入标签\n",
    "    target = np.load(targetData)\n",
    "    \n",
    "    #切分数据\n",
    "#     train_set,train_tag,test_set,test_tag = splitData(target,lsiDataSet)\n",
    "    \n",
    "    train_set,train_tag,test_set,test_tag = splitData(target,ldaDataSet)\n",
    "    \n",
    "    # 把一维的标签做onehot，pd.get_dummies的结果是df,把df转为ndarray (as_matrix())\n",
    "    train_label = pd.get_dummies(train_tag).as_matrix()\n",
    "    test_label = pd.get_dummies(test_tag).as_matrix()\n",
    "    \n",
    "    # 训练\n",
    "    trainModel_dense(train_set,train_label,test_set,test_label)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
