{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- encoding: utf-8 -*-\n",
    "import sys\n",
    "import codecs\n",
    "import csv\n",
    "import MeCab\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re, pprint\n",
    "def pp(obj):\n",
    "    pp = pprint.PrettyPrinter(indent=4, width=160)\n",
    "    str = pp.pformat(obj)\n",
    "    return re.sub(r\"\\\\u([0-9a-f]{4})\", lambda x: unichr(int(\"0x\"+x.group(1),16)), str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 读取停用词一览\n",
    "def readStopWord(ssfile):\n",
    "    ss = []\n",
    "    fr = open(ssfile,\"r\")\n",
    "    for line in fr.readlines():\n",
    "        line = line.strip()\n",
    "        if line != '':\n",
    "            ss.append(line)\n",
    "    fr.close()\n",
    "    return ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 读取CSV文件\n",
    "def readDataFile(fileName):\n",
    "    with open(fileName,\"r+\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        # skip header\n",
    "        header = next(reader)   \n",
    "#         print \"Read article:\",fileName\n",
    "        # 读取内容\n",
    "        for line in reader:\n",
    "            return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 获取词汇本体\n",
    "def get_surfaces(node):\n",
    "    words = []\n",
    "    while node:\n",
    "#         word  = node.surface.decode('utf-8')\n",
    "        word  = node.surface\n",
    "        words.append(word)\n",
    "        node = node.next\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 获取词性\n",
    "def get_nouns(node):\n",
    "    nouns = []\n",
    "    while node:\n",
    "#         noun = node.feature.split(\",\")[0].decode('utf-8')\n",
    "        noun = node.feature.split(\",\")[0]\n",
    "        nouns.append(noun)\n",
    "        node = node.next\n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 利用词性筛选词汇\n",
    "def select_feature(data,attr):\n",
    "    result = []\n",
    "    pattern1 = re.compile(r'[^0-9]+')\n",
    "    pattern2 = re.compile(ur'[^０１２３４５６７８９]+')\n",
    "    pattern3 = re.compile(ur'[^\\[\\]!$%&\\'\\\"\\(\\):\\-\\.,/;=<>]+')\n",
    "    pattern4 = re.compile(ur'[^！　％、。）※「」（＞～』＜？－．♪【⇒∞★〇・⇔]+')\n",
    "    for (w,a) in data:\n",
    "        if a in attr:\n",
    "#             print w,a\n",
    "            # 过滤所有数字\n",
    "            tmp = w.decode('utf-8')\n",
    "            matcher1 = re.match(pattern1,w)\n",
    "            matcher2 = re.match(pattern2,tmp)\n",
    "            matcher3 = re.match(pattern3,tmp)\n",
    "            matcher4 = re.match(pattern4,tmp)\n",
    "            if (matcher1 is not None) and (matcher2 is not None) and (matcher3 is not None) and (matcher4 is not None):\n",
    "#                 print w,a\n",
    "                result.append((w,a))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 把筛选以后的结果写入txt文件\n",
    "def writeOutput(fileName,data,mode):\n",
    "    fw = open(fileName,mode)\n",
    "    line = \"\"\n",
    "    for w in data:\n",
    "        line = line + w + \"\\t\"\n",
    "    fw.writelines( line  + \"\\n\")\n",
    "    fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 输出结果有两个文件\n",
    "# 全量分词结果文件：ALLWORD_filename\n",
    "# 词性筛选结果文件：mode_file (默认筛选名词 mode = \"N\")\n",
    "# 筛选 形容詞 ：mode 指定 \"A\"\n",
    "# 筛选 动词 ：mode 指定 \"V\"\n",
    "# 例如：筛选 名词，形容词的场合 :mode = \"NA\"\n",
    "def processFile(inPath,outPath,stopwords,mode=\"N\"):\n",
    "    \n",
    "    # 获取文件列表\n",
    "    fileList = os.listdir(inPath)\n",
    "    \n",
    "    for f in fileList:\n",
    "        \n",
    "        print \"-----Processing File:\",f\n",
    "        # 编辑文件路径\n",
    "        fileName = inPath + f\n",
    "        # 获取文章类别(验证用)\n",
    "        catlog = f.split(\".\")[0].split(\"-\")[-1]\n",
    "        # 获取文件内容\n",
    "        content = readDataFile(fileName)\n",
    "        # 获取文章标题\n",
    "        title = catlog + \"#\" + content[0]\n",
    "#         print \"title=\",title\n",
    "        # 定义分词器\n",
    "        mt = MeCab.Tagger('mecabrc')\n",
    "        node = mt.parseToNode(content[1])\n",
    "        words, nouns = get_surfaces(node), get_nouns(node)\n",
    "        wordList = zip(words,nouns)\n",
    "\n",
    "        attr = [u'名詞']\n",
    "        \n",
    "        if \"A\" in mode:\n",
    "            # 筛选形容詞结果写入CSV\n",
    "            attr.append(u'形容詞')\n",
    "  \n",
    "        if \"V\" in mode:\n",
    "            # 筛选動詞结果写入CSV\n",
    "            attr.append(u'動詞')\n",
    "        \n",
    "        # 筛选名词结果写入CSV\n",
    "        selectList = select_feature(wordList,attr)\n",
    "\n",
    "        #把文章标题加载每一行的第一个位置\n",
    "        outWord = []\n",
    "        outWord.append(title)\n",
    "        # 去掉停用词\n",
    "        for (w,a) in selectList:\n",
    "#             print \"w=\",w\n",
    "            if w not in stopwords:\n",
    "                outWord.append(w)\n",
    "        writeOutput(outPath,outWord,\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processAll():\n",
    "    # 读入停用词一览\n",
    "    ssfile = \"./conf/Japanese_stopwords.txt\"\n",
    "    ssList = readStopWord(ssfile)\n",
    "    \n",
    "    input_path = [\"/home/hadoop/Crawler/bus_all/\",\n",
    "                  \"/home/hadoop/Crawler/ent/\",\n",
    "                  \"/home/hadoop/Crawler/ind/\",\n",
    "                  \"/home/hadoop/Crawler/int/\",\n",
    "                  \"/home/hadoop/Crawler/life/\",\n",
    "                  \"/home/hadoop/Crawler/pol/\",\n",
    "                  \"/home/hadoop/Crawler/prod/\",\n",
    "                  \"/home/hadoop/Crawler/sci/\",\n",
    "                  \"/home/hadoop/Crawler/soci/\",\n",
    "                  \"/home/hadoop/Crawler/spo/\"]  \n",
    "    output_path = \"/home/hadoop/Crawler/all.txt\"\n",
    "    \n",
    "    # 筛选名词    \n",
    "#     processFile(input_path,output_path,\"N\")\n",
    "    # 筛选名词和形容次\n",
    "#     processFile(input_path,output_path,\"NA\")\n",
    "    # 筛选名词和形容次，动词\n",
    "#     processFile(input_path,output_path,\"NAV\")\n",
    "    for p in input_path:\n",
    "        print \"Process Folder:\",p\n",
    "        processFile(p,output_path,ssList,\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processTest():\n",
    "    \n",
    "    # 读入停用词一览\n",
    "    ssfile = \"./conf/Japanese_stopwords.txt\"\n",
    "    ssList = readStopWord(ssfile)\n",
    "       \n",
    "    input_path = [\"/home/hadoop/DataSencise/text_data/test/\"] \n",
    "    output_path = \"/home/hadoop/DataSencise/text_data/test/test.txt\"\n",
    "    \n",
    "    # 筛选名词    \n",
    "#     processFile(input_path,output_path,\"N\")\n",
    "    # 筛选名词和形容次\n",
    "#     processFile(input_path,output_path,\"NA\")\n",
    "    # 筛选名词和形容次，动词\n",
    "#     processFile(input_path,output_path,\"NAV\")\n",
    "    for p in input_path:\n",
    "        print \"Process Folder:\",p\n",
    "        processFile(p,output_path,ssList,\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # 处理全体数据\n",
    "#     processAll()\n",
    "    \n",
    "    # 处理测试数据\n",
    "    processTest()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
